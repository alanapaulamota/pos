{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Pós-graduação em Ciência de Dados e Machine Learning\n",
        "\n",
        "#### Disciplina: **Introdução a Redes Neurais**\n",
        "\n",
        "#### Projeto Final para disciplina Introdução a Redes Neurais\n",
        "\n",
        "<BR>\n",
        "    \n",
        "\n",
        "#### Nome dos integrantes:  \n",
        "#### RA: Alana Paula Barbosa Mota\n"
      ],
      "metadata": {
        "id": "1KAPZYnPUXZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** RESUMO: Deep Transfer Learning for Image Classification - https://arxiv.org/abs/1811.02685**\n",
        "\n",
        "\n",
        "O autor discute como, em muitas aplicações de aprendizado profundo, a disponibilidade de grandes volumes de dados rotulados é limitada, o que dificulta o treinamento de modelos complexos como redes neurais convolucionais (CNNs) do zero. Para lidar com isso, o transfer learning é uma solução eficaz. Ele propõe reutilizar modelos treinados em grandes conjuntos de dados, como o ImageNet, e adaptá-los para novas tarefas com menos dados.\n",
        "\n",
        "**Técnicas e Teorias**\n",
        "\n",
        "\n",
        "\n",
        "*   Transferência de aprendizado com CNNs: Utilização de ResNet como extrator de características.\n",
        "*   Fine-Tuning: Ajustar camadas finais do modelo para novos dados, evitando overfitting.\n",
        "*   Aumento de Dados: Geração de variações nas imagens de treino para maior robustez.\n",
        "*   Uso de Redes Profundas Pré-Treinadas: O autor discute várias arquiteturas de redes convolucionais profundas (CNNs), como ResNet e VGG, que foram treinadas em conjuntos de dados extensos.\n",
        "\n",
        "O artigo demonstra a eficácia do aprendizado por transferência para melhorar a precisão de classificação em tarefas com dados limitados e oferece insights práticos sobre como aplicar essas técnicas em projetos reais de deep learning. O uso de redes como ResNet50 possibilita soluções eficazes para a classificação de imagens, reduzindo a necessidade de grandes volumes de dados e alto custo computacional.\n",
        "\n",
        "\n",
        "---\n",
        "# Base de dados [Food-101 ](https://www.kaggle.com/datasets/hari31416/food-101?phase=FinishSSORegistration&returnUrl=%2Fdatasets%2Fhari31416%2Ffood-101%2Fversions%2F1%3Fresource%3Ddownload&SSORegistrationToken=CfDJ8KWOACvMaNFPiIJ818QpJK1Y5nCdELIm1VzSY_Wxic54iB_oX07r2BH8OqWSv15wKQD_w0AoE00A9yndUAA9YcQHz7Z1aGxz8uQ1ORHcM2FaIo4IEcmVCez-5Bpm30H6_rI8uVQ31pJhhaoUtEbfETvn8JGSrngXHznRaRTntqtNosNERtRu4hI36NkyYn6X1J0B9pK4cfsBwjMYJJbECXP2ZfIbeXz3NL77RJB56Em3xT1GxY3ev2EONNCNsCdyPZ-XsV7yQFLG-be5EArkHH380v6b0QqPDxmB7RYdFywUWpet92ojuZF0WDKl9_Jae2ki2GyV3-p-XoJrLPzJBbeBWSGtFw&DisplayName=Alana+Paula)\n",
        "\n",
        "\n",
        "A base de dados Food-101 foi selecionada para ser utilizada no processo de identificação de alimentos. Essa abordagem tem se tornado amplamente utilizada no campo da nutrição, visando identificar diferentes tipos de alimentos por meio de imagens. Isso facilita cálculos nutricionais automáticos, avaliando características dos alimentos como macronutrientes, valor e qualidade nutricional. Além disso, essas técnicas vêm sendo aplicadas no desenvolvimento de dietas preventivas, principalmente voltadas ao combate da obesidade e outras doenças relacionadas à alimentação. Com a ajuda de redes neurais e algoritmos de deep learning, é possível criar sistemas que auxiliam na avaliação nutricional e no planejamento de dietas personalizadas.\n",
        "\n",
        "**Aplicação para o Food-101:**\n",
        "\n",
        "\n",
        "*   Uso de Modelos Pré-treinados: contém 101 classes de alimentos com 101.000 imagens. Modelos pré-treinados, como ResNet ou VGG, já foram treinados em grandes bases de dados como ImageNet, que inclui várias imagens relacionadas a alimentos.\n",
        "*   Fine-Tuning para Identificação Específica: Ajustar as últimas camadas da rede (fine-tuning) permitirá que o modelo se especialize na distinção entre diferentes alimentos.\n",
        "*   Aumento de Dados (Data Augmentation): Aumentar os dados da Food-101 por meio de técnicas como rotação, corte e flip horizontal pode gerar novas imagens sintéticas que ajudam a melhorar a generalização do modelo, como recomendado no artigo. Evitando o overfitting\n",
        "*   Automação para Cálculos Nutricionais e Dieta: Ao identificar alimentos, o sistema pode ser integrado a um banco de dados nutricional, para calcular automaticamente valores nutricionais com base na imagem identificada.\n",
        "\n"
      ],
      "metadata": {
        "id": "XH1SUJ5VW_kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "1jhn3ciZJOMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 1: Importar as bibliotecas necessárias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "udBmBFdKWLGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsSF8gyTIUAx",
        "outputId": "1555a357-1150-4489-cee8-f40982919291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para o arquivo zip\n",
        "dataset = '/content/drive/MyDrive/CNN/archive.zip'\n",
        "\n",
        "# Criar um diretório para extrair os dados, se ainda não existir\n",
        "extract_dir = '/content/drive/MyDrive/datasets/food-101'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extrair o arquivo zip\n",
        "with zipfile.ZipFile(dataset, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "uQRTEDyBHGy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 2: Carregar o modelo pré-treinado ResNet50 sem as camadas de saída (sem incluir a parte de classificação)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "hJFzqzYuGM2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 3: Congelar as camadas da base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "jzRd2jBvGRZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 4: Adicionar novas camadas de classificação no topo do modelo\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(101, activation='softmax')(x)  # 101 classes"
      ],
      "metadata": {
        "id": "B_ntrVKrGTo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 5: Criar o modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "VB2UYtXAGUH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 6: Compilar o modelo com o otimizador Adam\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WMM_TQ23GXJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 7: Pré-processar os dados\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=40,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "JYoZFlWYhX_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 8: Carregar os dados de treino e validação\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/datasets/food-101/food-101/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/datasets/food-101/food-101/validation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "k9G8Xl2hhdKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 9: Configurar callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "-VZggueyjvm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 10: Treinar o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // 32,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // 32,\n",
        "    epochs=30,\n",
        "    callbacks=[checkpoint, lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "id": "OuB8HoOzhkPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 11: Avaliar o modelo\n",
        "score = model.evaluate(validation_generator)\n",
        "print(f'Acurácia no conjunto de validação: {score[1] * 100:.2f}%')"
      ],
      "metadata": {
        "id": "8r_xHJ75hn35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 12: Obter previsões e relatórios\n",
        "y_true = validation_generator.classes\n",
        "y_pred = model.predict(validation_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes))"
      ],
      "metadata": {
        "id": "PmBJAG93i8QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 13: Visualizar gráficos de desempenho\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Gráfico de Acurácia\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
        "plt.title('Acurácia do Modelo')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.xlabel('Épocas')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "YSNJTO1bZqdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de Perda\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
        "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
        "plt.title('Perda do Modelo')\n",
        "plt.ylabel('Perda')\n",
        "plt.xlabel('Épocas')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WkDbcLiujEJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Etapa 10: Salvando o modelo treinado\n",
        "model.save('modelo_transfer_nutri.h5')"
      ],
      "metadata": {
        "id": "kB-Coyz9Gh5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}